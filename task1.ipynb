{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a19db8c",
   "metadata": {},
   "source": [
    "## README\n",
    "1、这是机器学习实践对抗项目的全部具体实现代码和实验结果，如果想要运行，直接运行全部即可。\n",
    "\n",
    "2、由于作者本人硬件限制，本项目编写中并未提供GPU加速的选项，代码全部运行（包括对抗样本生成）大约需要5-10小时（参考计算资源：CPU AMD R7-4800U）。\n",
    "\n",
    "3、本文件中有许多弃用代码，为先前使用但后来被放弃的攻击算法，将其注释符号去掉后即可运行,但可能存在部分错误或仅计算了部分数据集的情况。\n",
    "\n",
    "4、随本文件附带了生成的对抗样本，如果需要重新生成，将下方的recal参数改为True即可。\n",
    "\n",
    "5、代码中对生成样本的扰动范围的限制均已注释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4816037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms as tt\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "from PIL import Image as pil\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#图片集路径设置\n",
    "image_path=\"images\"\n",
    "old_label_path=\"images//old_labels\"\n",
    "image_list=os.listdir(image_path)\n",
    "\n",
    "#是否重新生成对抗样本\n",
    "recal=True\n",
    "\n",
    "\n",
    "#图片大小数据224在代码中直接使用了，故无法适用其他大小的图片\n",
    "#模型导入\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "vit = timm.create_model('vit_small_patch16_224', pretrained=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1da5b6",
   "metadata": {},
   "source": [
    "## 图片导入与数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd2423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#助教提供的预处理函数\n",
    "def normalize(x, mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]):\n",
    "    mean_t = torch.Tensor(mean).reshape([1,3,1,1]).to(x.device)\n",
    "    std_t = torch.Tensor(std).reshape([1,3,1,1]).to(x.device)\n",
    "    y = (x-mean_t)/std_t\n",
    "    return y\n",
    "\n",
    "def get_preprocess(model_name):\n",
    "    if model_name[:6]==\"resnet\":\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    elif model_name[:3]==\"vit\":\n",
    "        mean=[0.5,0.5,0.5]\n",
    "        std=[0.5,0.5,0.5]\n",
    "    def preprocess(images):\n",
    "        y = F.interpolate(images.unsqueeze(0),224)\n",
    "        return normalize(y, mean=mean,\n",
    "                                 std=std)\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7c171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集类的构建与实例化\n",
    "\n",
    "class mydata1(Dataset):                          #适用res\n",
    "    def __init__(self,image_path):\n",
    "        self.file=[]\n",
    "        for i in open(old_label_path):\n",
    "            self.file.append(i)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=pil.open(\"images//\"+self.file[idx].split(' ')[0])\n",
    "        label=np.array(int(self.file[idx].split(' ')[1]))\n",
    "        img=preprocess1(tt.ToTensor()(img))\n",
    "        return img[0], label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "    \n",
    "    \n",
    "class mydata2(Dataset):                          #适用vit\n",
    "    def __init__(self,image_path):\n",
    "        self.file=[]\n",
    "        for i in open(old_label_path):\n",
    "            self.file.append(i)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=pil.open(\"images//\"+self.file[idx].split(' ')[0])\n",
    "        label=np.array(int(self.file[idx].split(' ')[1]))\n",
    "        img=preprocess2(tt.ToTensor()(img))\n",
    "        return img[0], label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "preprocess1=get_preprocess(\"resnet\")\n",
    "res_data_Tensor = torch.utils.data.DataLoader(dataset=mydata1(image_path))\n",
    "preprocess2=get_preprocess(\"vit\")\n",
    "vit_data_Tensor=torch.utils.data.DataLoader(dataset=mydata2(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3d0b1",
   "metadata": {},
   "source": [
    "##  测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289a1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_Tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_Tensor:\n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            correct=correct+(pred_y == labels)\n",
    "            total=total+1\n",
    "        accuracy = correct / float(total)\n",
    "            \n",
    "    print('Test Accuracy of the model on the 1000 test images: %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1165ae8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.950\n"
     ]
    }
   ],
   "source": [
    "#res模型在提供的数据集上的精度\n",
    "test(resnet50,res_data_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da017454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.978\n"
     ]
    }
   ],
   "source": [
    "#vit模型在提供的数据集上的精度\n",
    "test(vit,vit_data_Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca442984",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0388b5",
   "metadata": {},
   "source": [
    "## 白盒攻击"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916a885",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e75dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\ndef fgm(model, image, label, epsilon, order, clip_min, clip_max, device):\\n    imageArray = image.cpu().detach().numpy()\\n    X_fgsm = torch.tensor(imageArray).to(device)\\n    X_fgsm.requires_grad = True\\n    opt = optim.SGD([X_fgsm], lr=1e-3)\\n    opt.zero_grad()\\n    loss = nn.CrossEntropyLoss()(model(X_fgsm), label.long())\\n    loss.backward()\\n    if order == np.inf:\\n        d = epsilon * X_fgsm.grad.data.sign()\\n    elif order == 2:\\n        gradient = X_fgsm.grad\\n        d = torch.zeros(gradient.shape, device = device)\\n        for i in range(gradient.shape[0]):\\n            norm_grad = gradient[i].data/LA.norm(gradient[i].data.cpu().numpy())\\n            d[i] = norm_grad * epsilon\\n    else:\\n        raise ValueError(\\'Other p norms may need other algorithms\\')\\n\\n    x_adv = X_fgsm + d\\n\\n    if clip_max == None and clip_min == None:\\n        clip_max = np.inf\\n        clip_min = -np.inf\\n\\n    x_adv = torch.clamp(x_adv,clip_min, clip_max)\\n\\n    return x_adv\\n        \\n\\ndef fgsm_attack(model,input_Tensor,epsilon,lim):\\n    fgsm_sample_list=[]\\n    id=0\\n    for (data, target) in input_Tensor:\\n        perturbed_data = fgm(model,data,target,epsilon,2,0,1,\"cpu\")\\n        fgsm_sample_list.append((perturbed_data,target))\\n        id=id+1\\n        if(id%100==0):\\n            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\\n        \\n    return fgsm_sample_list\\n    \\n    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "经测试后弃用\n",
    "\n",
    "def fgm(model, image, label, epsilon, order, clip_min, clip_max, device):\n",
    "    imageArray = image.cpu().detach().numpy()\n",
    "    X_fgsm = torch.tensor(imageArray).to(device)\n",
    "    X_fgsm.requires_grad = True\n",
    "    opt = optim.SGD([X_fgsm], lr=1e-3)\n",
    "    opt.zero_grad()\n",
    "    loss = nn.CrossEntropyLoss()(model(X_fgsm), label.long())\n",
    "    loss.backward()\n",
    "    if order == np.inf:\n",
    "        d = epsilon * X_fgsm.grad.data.sign()\n",
    "    elif order == 2:\n",
    "        gradient = X_fgsm.grad\n",
    "        d = torch.zeros(gradient.shape, device = device)\n",
    "        for i in range(gradient.shape[0]):\n",
    "            norm_grad = gradient[i].data/LA.norm(gradient[i].data.cpu().numpy())\n",
    "            d[i] = norm_grad * epsilon\n",
    "    else:\n",
    "        raise ValueError('Other p norms may need other algorithms')\n",
    "\n",
    "    x_adv = X_fgsm + d\n",
    "\n",
    "    if clip_max == None and clip_min == None:\n",
    "        clip_max = np.inf\n",
    "        clip_min = -np.inf\n",
    "\n",
    "    x_adv = torch.clamp(x_adv,clip_min, clip_max)\n",
    "\n",
    "    return x_adv\n",
    "        \n",
    "\n",
    "def fgsm_attack(model,input_Tensor,epsilon,lim):\n",
    "    fgsm_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        perturbed_data = fgm(model,data,target,epsilon,2,0,1,\"cpu\")\n",
    "        fgsm_sample_list.append((perturbed_data,target))\n",
    "        id=id+1\n",
    "        if(id%100==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return fgsm_sample_list\n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096a618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepsilon=0.3\\nlim=\"l_2\"\\nfgsm_sample={}\\nfgsm_sample_path=\\'./fgsm_sample.txt\\'\\nfgsm_sample[\"res\"]=fgsm_attack(resnet50, res_data_Tensor,epsilon,lim)\\n\\nfgsm_sample[\"vit\"]=fgsm_attack(vit, vit_data_Tensor,epsilon,lim)\\n\\nwith open(fgsm_sample_path,\\'wb\\') as f:\\n    content = pickle.dumps(fgsm_sample)\\n    f.write(content)\\n    \\ntest(resnet50,fgsm_sample[\"res\"])\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "经测试后弃用\n",
    "epsilon=0.3\n",
    "lim=\"l_2\"\n",
    "fgsm_sample={}\n",
    "fgsm_sample_path='./fgsm_sample.txt'\n",
    "fgsm_sample[\"res\"]=fgsm_attack(resnet50, res_data_Tensor,epsilon,lim)\n",
    "\n",
    "fgsm_sample[\"vit\"]=fgsm_attack(vit, vit_data_Tensor,epsilon,lim)\n",
    "\n",
    "with open(fgsm_sample_path,'wb') as f:\n",
    "    content = pickle.dumps(fgsm_sample)\n",
    "    f.write(content)\n",
    "    \n",
    "test(resnet50,fgsm_sample[\"res\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75df54f",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddafd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdg攻击样本生成函数\n",
    "\n",
    "def pgd(model,X,y,epsilon,num_steps,step_size,bound = 'linf'):\n",
    "    out = model(X)\n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    \n",
    "    device = X.device\n",
    "    imageArray = X.detach().cpu().numpy()\n",
    "    X_random = np.random.uniform(-epsilon, epsilon, X.shape)\n",
    "    imageArray = np.clip(imageArray + X_random, 0, 1.0)\n",
    "\n",
    "    X_pgd = torch.tensor(imageArray).to(device).float()\n",
    "    X_pgd.requires_grad = True\n",
    "    eta = torch.zeros_like(X)\n",
    "    eta.requires_grad = True\n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        \n",
    "\n",
    "        if bound == 'linf':\n",
    "            output = model(X + eta)\n",
    "            incorrect = output.max(1)[1] != y\n",
    "            correct = (~incorrect).unsqueeze(1).unsqueeze(1).unsqueeze(1).float()\n",
    "            loss = nn.CrossEntropyLoss()(model(X + eta), y.long())\n",
    "            loss.backward()\n",
    "            eta.data +=  correct *step_size* eta.grad.detach().data.sign()        \n",
    "            eta.data =torch.clamp(eta.detach(),-epsilon,epsilon)                    #将扰动限制在epsilon范围内\n",
    "            eta.data =   torch.min(torch.max(eta.detach(), -X), 1-X)                #将每位数据限制在[0，1]\n",
    "            eta.grad.zero_()\n",
    "            X_pgd = X + eta\n",
    "            \n",
    "\n",
    "        if bound == 'l2':\n",
    "            output = model(X + eta)\n",
    "            incorrect = output.max(1)[1] != y\n",
    "            correct = (~incorrect).unsqueeze(1).unsqueeze(1).unsqueeze(1).float()\n",
    "            loss = nn.CrossEntropyLoss()(model(X + eta), y.long())\n",
    "            loss.backward()\n",
    "            eta.data +=  correct * step_size * eta.grad.detach() / torch.norm(eta.grad.detach())\n",
    "            eta.data *=  epsilon / torch.norm(eta.detach())                        #将扰动限制在epsilon范围内\n",
    "            eta.data =   torch.min(torch.max(eta.detach(), -X), 1-X)               #将每位数据限制在[0，1]\n",
    "            eta.grad.zero_()\n",
    "            X_pgd = X + eta\n",
    "    return X_pgd\n",
    "\n",
    "def pgd_attack(model,input_Tensor,epsilon,num_steps,step_size,bound = 'linf'):\n",
    "    pgd_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        perturbed_data = pgd(model,data,target,epsilon,num_steps,step_size,bound = 'linf')\n",
    "        pgd_sample_list.append((perturbed_data,target))\n",
    "        id=id+1\n",
    "        #if(id==50):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return pgd_sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3eff4",
   "metadata": {},
   "source": [
    "#### l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4ec317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n",
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n"
     ]
    }
   ],
   "source": [
    "#l_2攻击样本生成/读取\n",
    "\n",
    "pgd_sample_path='./pgd_sample.txt'\n",
    "epsilon=0.3\n",
    "if recal:\n",
    "    pgd_sample={}\n",
    "    pgd_sample[\"res\"]=pgd_attack(resnet50,res_data_Tensor,epsilon,2,epsilon,'l2')\n",
    "    pgd_sample[\"vit\"]=pgd_attack(vit,vit_data_Tensor,epsilon,2,epsilon,'l2')\n",
    "    with open(pgd_sample_path,'wb') as f:\n",
    "        content = pickle.dumps(pgd_sample)\n",
    "        f.write(content)\n",
    "else:\n",
    "    with open(pgd_sample_path,'rb') as f:\n",
    "        pgd_sample=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0295cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.002\n"
     ]
    }
   ],
   "source": [
    "test(resnet50,pgd_sample[\"res\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b464ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.000\n"
     ]
    }
   ],
   "source": [
    "test(vit,pgd_sample[\"vit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f862a",
   "metadata": {},
   "source": [
    "#### linf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe4b07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n",
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n"
     ]
    }
   ],
   "source": [
    "#l_inf攻击样本生成\n",
    "\n",
    "pgd_inf_sample_path='./pgd_inf_sample.txt'\n",
    "epsilon=1/255.0\n",
    "if recal:\n",
    "    pgd_inf_sample={}\n",
    "    pgd_inf_sample[\"res\"]=pgd_attack(resnet50,res_data_Tensor,epsilon,10,epsilon/5,'linf')\n",
    "    pgd_inf_sample[\"vit\"]=pgd_attack(vit,vit_data_Tensor,epsilon,10,epsilon/5,'linf')\n",
    "    with open(pgd_inf_sample_path,'wb') as f:\n",
    "        content = pickle.dumps(pgd_inf_sample)\n",
    "        f.write(content)\n",
    "    \n",
    "else:\n",
    "    with open(pgd_inf_sample_path,'rb') as f:\n",
    "        pgd_inf_sample=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "491bee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.151\n"
     ]
    }
   ],
   "source": [
    "test(resnet50,pgd_inf_sample[\"res\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42fb6773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.290\n"
     ]
    }
   ],
   "source": [
    "test(vit,pgd_inf_sample[\"vit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e671e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85b11784",
   "metadata": {},
   "source": [
    "### patch_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45443367",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "攻击方案一：用梯度的模来判断patch的优劣\n",
    "\n",
    "def patch_attack(model,input_Tensor,patch_size):\n",
    "    patch_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1)[1].squeeze()\n",
    "        loss = nn.CrossEntropyLoss()(output, target.long())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = patch(data,patch_size,data_grad)\n",
    "        patch_sample_list.append((perturbed_data,target))\n",
    "        id=id+1\n",
    "        #if(id==100):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return patch_sample_list\n",
    "        \n",
    "def patch(data,patch_size,data_grad):\n",
    "    max_i=0\n",
    "    max=0\n",
    "    for i in range(0,(223-patch_size)):\n",
    "        temp=torch.norm(data_grad[:,:,i:i+patch_size,i:i+patch_size])\n",
    "        if(temp>max):\n",
    "            max=temp\n",
    "            max_i=i\n",
    "    #print(max)\n",
    "    #print(max_i)\n",
    "    \n",
    "    #print(mask[:,:,max_i:(max_i+patch_size),max_i:(max_i+patch_size)].size())\n",
    "    #mask.[max_i:(max_i+patch_size),max_i:(max_i+patch_size)],1)\n",
    "    \n",
    "    mask=torch.zeros((1,3,224,224))\n",
    "    mask[:,:,max_i:(max_i+patch_size),max_i:(max_i+patch_size)]=torch.ones((1,3,patch_size,patch_size))\n",
    "                                                                  #将改动范围限制在16*16的区域内\n",
    "    grad_attack = data_grad.sign()*mask\n",
    "    \n",
    "    result = data + grad_attack\n",
    "    result = torch.clamp(result, 0, 1)\n",
    "    return result\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db333a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#攻击方案二\n",
    "'''\n",
    "def patch_attack(model,input_Tensor,patch_size):\n",
    "    patch_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1)[1].squeeze()\n",
    "        loss = nn.CrossEntropyLoss()(output, target.long())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = patch(model,data,target,patch_size,data_grad)\n",
    "        patch_sample_list.append((perturbed_data,target))\n",
    "        id=id+1\n",
    "        #if(id==100):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return patch_sample_list\n",
    "        \n",
    "def patch(model,data,target,patch_size,data_grad):\n",
    "    max_i=0\n",
    "    max=0\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    for i in range(0,(223-patch_size),patch_size):\n",
    "        for j in range(0,(223-patch_size),patch_size):\n",
    "            mask=torch.zeros((1,3,224,224))\n",
    "            mask[:,:,i:(i+patch_size),j:(j+patch_size)]=torch.ones((1,3,patch_size,patch_size))\n",
    "                                                                             #将改动范围限制在16*16的区域内\n",
    "            grad_attack = data_grad.detach().sign()*mask\n",
    "            result1 = data + grad_attack.detach()\n",
    "\n",
    "            result1 = torch.clamp(result1.detach(), 0, 1)                    #将每位数据限制在[0，1]\n",
    "            temp=loss(model(result1),target.long())\n",
    "            if(temp>max):\n",
    "                max=temp.detach()\n",
    "                result=result1.detach()\n",
    "\n",
    "    #print(max)\n",
    "    #print(max_i)\n",
    "    \n",
    "    #print(mask[:,:,max_i:(max_i+patch_size),max_i:(max_i+patch_size)].size())\n",
    "    #mask.[max_i:(max_i+patch_size),max_i:(max_i+patch_size)],1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3016a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#攻击方案三\n",
    "\n",
    "def patch_attack(model,input_Tensor,patch_size,iters):\n",
    "    patch_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        data.requires_grad = True\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1)[1].squeeze()\n",
    "        loss = nn.CrossEntropyLoss()(output, target.long())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = patch(model,data,target,patch_size,data_grad,iters)\n",
    "        patch_sample_list.append((perturbed_data,target))\n",
    "        id=id+1\n",
    "        #if(id==100):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return patch_sample_list\n",
    "        \n",
    "def patch(model,data,target,patch_size,data_grad,iters):\n",
    "    max_i=0\n",
    "    max=0\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    for k in range(iters):\n",
    "        i=random.randint(0,223-patch_size)\n",
    "        j=random.randint(0,223-patch_size)\n",
    "        mask=torch.zeros((1,3,224,224))\n",
    "        mask[:,:,i:(i+patch_size),j:(j+patch_size)]=torch.ones((1,3,patch_size,patch_size))\n",
    "                                                                         #将改动范围限制在16*16的区域内\n",
    "        grad_attack = data_grad.detach().sign()*mask\n",
    "        \n",
    "        result1 = data + grad_attack.detach()\n",
    "\n",
    "        result1 = torch.clamp(result1.detach(), 0, 1)                    #将每位数据限制在[0，1]\n",
    "        temp=loss(model(result1),target.long())\n",
    "        if(temp>max):\n",
    "            max=temp.detach()\n",
    "            result=result1.detach()\n",
    "        \n",
    "\n",
    "    #print(max)\n",
    "    #print(max_i)\n",
    "    \n",
    "    #print(mask[:,:,max_i:(max_i+patch_size),max_i:(max_i+patch_size)].size())\n",
    "    #mask.[max_i:(max_i+patch_size),max_i:(max_i+patch_size)],1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a2eae37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n",
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n"
     ]
    }
   ],
   "source": [
    "patch_sample={}\n",
    "patch_sample_path='./patch_sample.txt'\n",
    "iters=10\n",
    "if recal:\n",
    "    patch_sample[\"res\"]=patch_attack(resnet50,res_data_Tensor,16,iters)\n",
    "    patch_sample[\"vit\"]=patch_attack(vit,vit_data_Tensor,16,iters)\n",
    "    with open(patch_sample_path,'wb') as f:\n",
    "        content = pickle.dumps(patch_sample)\n",
    "        f.write(content)\n",
    "else:\n",
    "    with open(patch_sample_path,'rb') as f:\n",
    "        patch_sample=pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "00c85e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.204\n"
     ]
    }
   ],
   "source": [
    "test(resnet50,patch_sample[\"res\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a90ab418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.768\n"
     ]
    }
   ],
   "source": [
    "test(vit,patch_sample[\"vit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae3ac1",
   "metadata": {},
   "source": [
    "## 黑盒攻击"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffb80c",
   "metadata": {},
   "source": [
    "### Query-based Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "def query_attack(model,input_Tensor,epsilon,budget):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    query_sample_list=[]\n",
    "    id=0\n",
    "    for (data, target) in input_Tensor:\n",
    "        data.requires_grad=True\n",
    "        y=model(data)\n",
    "        X=data\n",
    "        L_0=loss(y,target.long())\n",
    "        for i in range(budget):\n",
    "            noise=torch.rand(3,224,224)\n",
    "            X_new=torch.clamp((epsilon*noise/torch.norm(noise)+X),0,1)\n",
    "            L_1=loss(model(X_new),target.long())\n",
    "            if(L_1>L_0):\n",
    "                L_0=L_1\n",
    "                X=X_new\n",
    "            \n",
    "        \n",
    "        query_sample_list.append((X,target));\n",
    "        id=id+1\n",
    "        #if(id==100):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "    return query_sample_list\n",
    "        \n",
    "'''     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014bb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "epsilon=5\n",
    "budget=5\n",
    "query_sample={}\n",
    "query_sample_path='./query_sample.txt'\n",
    "if recal:\n",
    "    query_sample[\"res\"]=query_attack(resnet50,res_data_Tensor,epsilon,budget)\n",
    "    query_sample[\"vit\"]=query_attack(vit,vit_data_Tensor,epsilon,10)\n",
    "    with open(query_sample_path,'wb') as f:\n",
    "        content = pickle.dumps(query_sample)\n",
    "        f.write(content)\n",
    "else:\n",
    "    with open(query_sample_path,'rb') as f:\n",
    "        query_sample=pickle.load(f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(resnet50,query_sample[\"res\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(vit,query_sample[\"vit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c3b22",
   "metadata": {},
   "source": [
    "### simBA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b8d11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(model, x, y):\n",
    "    output = model(x)\n",
    "    probs = torch.nn.Softmax()(output)[:, y.long()]\n",
    "    return torch.diag(probs.data)\n",
    "\n",
    "def simba_single(model, x, y, num_iters=10000, epsilon=0.2):\n",
    "    n_dims = x.view(1, -1).size(1)\n",
    "    X=x\n",
    "    perm = torch.randperm(n_dims)\n",
    "    last_prob = get_probs(model, x, y)\n",
    "    for i in range(num_iters):\n",
    "        diff = torch.zeros(n_dims)\n",
    "        diff[perm[i]] = epsilon\n",
    "        left_prob = get_probs(model, (X - diff.view(X.size())).clamp(0, 1), y)\n",
    "        if left_prob < last_prob:\n",
    "            X = (X - diff.view(X.size())).clamp(0, 1)                                \n",
    "            last_prob = left_prob\n",
    "        else:\n",
    "            right_prob = get_probs(model, (X + diff.view(X.size())).clamp(0, 1), y)\n",
    "            if right_prob < last_prob:\n",
    "                X = (X + diff.view(X.size())).clamp(0, 1)                            \n",
    "                last_prob = right_prob\n",
    "    X=(X-x)*epsilon/torch.norm(X-x)+x                                    #将扰动限制在epsilon范围内\n",
    "    X=X.clamp(0,1)                                                       #将每位数据限制在[0，1]\n",
    "    return X\n",
    "\n",
    "def simba(model,input_Tensor,num_iters,epsilon):\n",
    "    simba_sample_list=[]\n",
    "    id=0\n",
    "    for (data,target) in input_Tensor:\n",
    "        simba_sample_list.append((simba_single(model,data,target,num_iters,epsilon),target))\n",
    "        id=id+1\n",
    "        #if(id==100):break\n",
    "        if(id%50==0):\n",
    "            print((\"%d/\"+\"1000\"+\"\\r\")%(id))\n",
    "        \n",
    "    return simba_sample_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f701fea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-90d3c162cb91>:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = torch.nn.Softmax()(output)[:, y.long()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n",
      "50/1000\n",
      "100/1000\n",
      "150/1000\n",
      "200/1000\n",
      "250/1000\n",
      "300/1000\n",
      "350/1000\n",
      "400/1000\n",
      "450/1000\n",
      "500/1000\n",
      "550/1000\n",
      "600/1000\n",
      "650/1000\n",
      "700/1000\n",
      "750/1000\n",
      "800/1000\n",
      "850/1000\n",
      "900/1000\n",
      "950/1000\n",
      "1000/1000\n"
     ]
    }
   ],
   "source": [
    "epsilon=5\n",
    "num_iters=5\n",
    "simba_sample={}\n",
    "simba_sample_path='./simba_sample.txt'\n",
    "if recal:\n",
    "    simba_sample[\"res\"]=simba(resnet50,res_data_Tensor,num_iters,epsilon)\n",
    "    simba_sample[\"vit\"]=simba(vit,vit_data_Tensor,10,epsilon)\n",
    "    with open(simba_sample_path,'wb') as f:\n",
    "        content = pickle.dumps(simba_sample)\n",
    "        f.write(content)\n",
    "else:\n",
    "    with open(simba_sample_path,'rb') as f:\n",
    "        simba_sample=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4685cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.354\n"
     ]
    }
   ],
   "source": [
    "test(resnet50,simba_sample[\"res\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cf834a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1000 test images: 0.671\n"
     ]
    }
   ],
   "source": [
    "test(vit,simba_sample[\"vit\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
